{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine tuning for machine translation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q_U8NQvAkAB"
      },
      "source": [
        "# !pip install transformers\n",
        "# !pip install git+https://github.com/PytorchLightning/pytorch-lightning.git@master --upgrade\n",
        "# !pip install SentencePiece\n",
        "\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import json\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrufCjRlg5e9"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/susanli2016/NLP-with-Python/master/data/small_vocab_en\n",
        "!wget https://raw.githubusercontent.com/susanli2016/NLP-with-Python/master/data/small_vocab_fr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVzyy7rjk3fm"
      },
      "source": [
        "# Input - Two list of sentences\n",
        "english = []\n",
        "french = []\n",
        "with open(\"small_vocab_en\", \"r\") as english_file:\n",
        "  text = english_file.readlines()\n",
        "  text = [t.strip(\"\\n\") for t in text]\n",
        "  english.extend(text)\n",
        "\n",
        "with open(\"small_vocab_en\", \"r\") as french_file:\n",
        "  text = french_file.readlines()\n",
        "  text = [t.strip(\"\\n\") for t in text]\n",
        "  french.extend(text)\n",
        "\n",
        "data = pd.DataFrame({\"english\" : english, \"french\" : french})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNK0Ra7QvDce"
      },
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-YdY2GNn4HA"
      },
      "source": [
        "x = data[\"english\"].values.tolist()\n",
        "y = data[\"french\"].values.tolist()\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF8ZUJ3woOhl"
      },
      "source": [
        "train_encodings = tokenizer(train_x, padding=True, truncation=True)\n",
        "val_encodings = tokenizer(val_x, padding=True, truncation=True)\n",
        "with tokenizer.as_target_tokenizer():\n",
        "    train_labels = tokenizer(train_y, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    val_labels = tokenizer(val_y, padding=True, truncation=True, return_tensors=\"pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sFkwhIfoWiE"
      },
      "source": [
        "# Dataset class\n",
        "\n",
        "class MTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[\"input_ids\"][idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = MTDataset(train_encodings, train_labels)\n",
        "val_dataset = MTDataset(val_encodings, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfs2kCGNpI0b"
      },
      "source": [
        "# Train the model\n",
        "\n",
        "idx = 0\n",
        "model_path = f'gdrive/MyDrive/model_{idx}'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_path,          # output directory\n",
        "    num_train_epochs=1, \n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size = 1          \n",
        ")\n",
        "\n",
        "# Trainer object \n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         \n",
        "    args=training_args,                 \n",
        "    train_dataset=train_dataset,        \n",
        "    eval_dataset=val_dataset             \n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fLwjASept2U"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P9sLEvs4avt"
      },
      "source": [
        "!mkdir here\n",
        "trainer.save_model(\"here\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}