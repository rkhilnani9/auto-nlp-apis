{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine tuning for sentiment analysis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ652SHHDHLD"
      },
      "source": [
        "# !pip install transformers\n",
        "# !pip install git+https://github.com/PytorchLightning/pytorch-lightning.git@master --upgrade\n",
        "\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from transformers import DistilBertTokenizer\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9KNsv9cIxP0"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/YJiangcm/SST-2-sentiment-analysis/master/data/train.tsv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS_SvN2oHICA"
      },
      "source": [
        "data = pd.read_csv(\"train.tsv\", sep=\"\\t\", header=None)\n",
        "data.columns = [\"label\", \"text\"]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXvS6syNHOMh"
      },
      "source": [
        "x = data[\"text\"].values\n",
        "y = data[\"label\"].values\n",
        "\n",
        "# Split into training and validation sets\n",
        "\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(x, y)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4CCnupAIzND"
      },
      "source": [
        "# Load pre-trained DistilBertTokenizer\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zCRtf_LIYw5"
      },
      "source": [
        "# Tokenize\n",
        "\n",
        "train_tokens = tokenizer(list(train_data), return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "val_tokens = tokenizer(list(val_data), return_tensors=\"pt\", padding=True, truncation=True, max_length=64)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhsgc_EfGGtS"
      },
      "source": [
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "\n",
        "class ClassificationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = ClassificationDataset(train_tokens, train_labels)\n",
        "val_dataset = ClassificationDataset(val_tokens, val_labels)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Iy-ylpfJuCv"
      },
      "source": [
        "# Train the model\n",
        "idx = 0\n",
        "model_path = f'gdrive/MyDrive/model_{idx}'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_path,          # output directory\n",
        "    num_train_epochs=1, \n",
        "    evaluation_strategy=\"epoch\"             # total number of training epochs\n",
        ")\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Trainer object \n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         \n",
        "    args=training_args,                 \n",
        "    train_dataset=train_dataset,        \n",
        "    eval_dataset=val_dataset             \n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktKuoRpHJunP"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFaH-rJDJyls"
      },
      "source": [
        "!mkdir here\n",
        "trainer.save_model(\"here\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}